{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04d879",
   "metadata": {
    "cellId": "9hhxev8rmihyd1qlflsc3a"
   },
   "outputs": [],
   "source": [
    "# %pip install requests urllib if needed\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlencode\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import requests\n",
    "\n",
    "base_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download?\"\n",
    "public_key = \"https://disk.yandex.ru/d/5psHmaR1GCQq4w\"\n",
    "\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()[\"href\"]\n",
    "response = requests.get(download_url)\n",
    "\n",
    "dist_path = \"D\"\n",
    "zipfile = ZipFile(BytesIO(response.content))\n",
    "zipfile.extractall(path=dist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bc283560",
   "metadata": {
    "cellId": "f3dntsdfgveucm1vkalya",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:08:42.417858128Z",
     "iopub.status.busy": "2023-11-11T11:08:43.331249Z",
     "iopub.status.idle": "2023-11-11T11:08:43.364560Z",
     "shell.execute_reply": "2023-11-11T11:08:43.363828Z",
     "shell.execute_reply.started": "2023-11-11T11:08:43.332509Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from sys import getsizeof\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "video_path = \"Videos\"\n",
    "main_dir = \"/home/jupyter/work/resources/D/Stavropol\"\n",
    "model_dir = \"/home/jupyter/work/resources/D/Stavropol/models\"\n",
    "os.chdir(main_dir)\n",
    "\n",
    "\n",
    "def getClasses():\n",
    "    os.chdir(main_dir)\n",
    "    classes = []\n",
    "    with open(\"classes.csv\") as fp:\n",
    "        reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "        # next(reader, None)  # skip the headers\n",
    "        data_read = [row for row in reader]\n",
    "        classes = [x[1] for x in data_read[1:]]\n",
    "    return classes\n",
    "\n",
    "\n",
    "def createModel(classes):\n",
    "    input_shape = (None, 30, 30, 3)\n",
    "\n",
    "    model = models.Sequential()\n",
    " \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    \n",
    "    model.add(layers.ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
    "                                recurrent_dropout=0.2, return_sequences=True, input_shape = input_shape, name=\"LSTM1\"))\n",
    "    \n",
    "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last', name=\"MP1\"))\n",
    "    model.add(layers.TimeDistributed(layers.Dropout(0.2)))\n",
    "    \n",
    "    model.add(layers.ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                                recurrent_dropout=0.2, return_sequences=True, name=\"LSTM2\"))\n",
    "    \n",
    "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last', name=\"MP2\"))\n",
    "    model.add(layers.TimeDistributed(layers.Dropout(0.2)))\n",
    "    \n",
    "    model.add(layers.ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                                recurrent_dropout=0.2, return_sequences=True, name=\"LSTM3\"))\n",
    "    \n",
    "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last', name=\"MP3\"))\n",
    "    model.add(layers.TimeDistributed(layers.Dropout(0.2)))\n",
    "    \n",
    "    model.add(layers.ConvLSTM2D(filters = 16, kernel_size = (2, 2), activation = 'tanh', data_format = \"channels_last\",\n",
    "                                recurrent_dropout=0.2, return_sequences=True, name=\"LSTM4\"))\n",
    "    \n",
    "    model.add(layers.MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last', name=\"MP4\"))\n",
    "    #model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "    model.add(layers.GlobalAveragePooling3D()) \n",
    "    \n",
    "    model.add(layers.Dense(len(classes), activation = \"softmax\"))\n",
    "    \n",
    "    ########################################################################################################################\n",
    "     \n",
    "    # Display the models summary.\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Return the constructed convlstm model.\n",
    "    return model\n",
    "\n",
    "\n",
    "def getLabeledVideo(directory):\n",
    "    os.chdir(f\"{main_dir}/{directory}\")\n",
    "    categories = os.listdir()\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for category in range(len(categories)):\n",
    "        # print(f\"Категория: {categories[category]}\")\n",
    "        path = f\"{main_dir}/{directory}/{categories[category]}\"\n",
    "        os.chdir(path)\n",
    "        videos = os.listdir()\n",
    "        for video in videos:\n",
    "            video_path = os.getcwd() + f\"/{video}\"\n",
    "            x_data.append(video_path)\n",
    "            y_data.append(category)\n",
    "    return x_data, np.array(y_data)\n",
    "\n",
    "\n",
    "def getVideo(path_video):\n",
    "    vid_capture = cv2.VideoCapture(path_video)\n",
    "    video_numerized = []\n",
    "    if vid_capture.isOpened() == False:\n",
    "        print(\"Ошибка открытия видеофайла\")\n",
    "    else:\n",
    "        file_count = 0\n",
    "        while vid_capture.isOpened():\n",
    "            ret, frame = vid_capture.read()\n",
    "            if ret == True:\n",
    "                file_count += 1\n",
    "                frame = frame / 255.0\n",
    "                video_numerized.append(frame)\n",
    "            else:\n",
    "                break\n",
    "    return np.array(video_numerized)\n",
    "\n",
    "\n",
    "def batch_generator(x_data, y_data, batch_size):\n",
    "    for i in range(0, len(x_data), batch_size):\n",
    "        yield np.array(\n",
    "            list(map(getVideo, x_data[i : i + batch_size])), dtype=\"object\"\n",
    "        ), y_data[i : i + batch_size]\n",
    "\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size=(30, 30), frame_step=15):\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    result.append(format_frames(frame, output_size))\n",
    "\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "            if ret:\n",
    "                frame = format_frames(frame, output_size)\n",
    "                result.append(frame)\n",
    "            else:\n",
    "                result.append(np.zeros_like(result[0]))\n",
    "    src.release()\n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class FrameGenerator:\n",
    "    def __init__(self, video_paths, classes, n_frames, training=False):\n",
    "        \"\"\"Returns a set of frames with their associated label.\n",
    "\n",
    "        Args:\n",
    "          path: Video file paths.\n",
    "          n_frames: Number of frames.\n",
    "          training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.video_paths = video_paths\n",
    "        self.classes = classes\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        # self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        # self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob(\"*/*.avi\"))\n",
    "        classes = [p.parent.name for p in video_paths]\n",
    "        return video_paths, classes\n",
    "\n",
    "    def __call__(self):\n",
    "        # video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "        pairs = list(zip(self.video_paths, self.classes))\n",
    "\n",
    "        # if self.training:\n",
    "        # random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames)\n",
    "            label = name  # self.class_ids_for_name[name] # Encode labels\n",
    "            yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d1eeb3a0",
   "metadata": {
    "cellId": "br23ul0qjlbbwe05shhvod",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:08:43.524250548Z",
     "iopub.status.busy": "2023-11-11T11:08:44.391450Z",
     "iopub.status.idle": "2023-11-11T11:08:44.860707Z",
     "shell.execute_reply": "2023-11-11T11:08:44.860121Z",
     "shell.execute_reply.started": "2023-11-11T11:08:44.392291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM1 (ConvLSTM2D)          (None, None, 28, 28, 4)   1024      \n",
      "                                                                 \n",
      " MP1 (MaxPooling3D)          (None, None, 14, 14, 4)   0         \n",
      "                                                                 \n",
      " time_distributed_39 (TimeDi  (None, None, 14, 14, 4)  0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " LSTM2 (ConvLSTM2D)          (None, None, 12, 12, 8)   3488      \n",
      "                                                                 \n",
      " MP2 (MaxPooling3D)          (None, None, 6, 6, 8)     0         \n",
      "                                                                 \n",
      " time_distributed_40 (TimeDi  (None, None, 6, 6, 8)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " LSTM3 (ConvLSTM2D)          (None, None, 4, 4, 14)    11144     \n",
      "                                                                 \n",
      " MP3 (MaxPooling3D)          (None, None, 2, 2, 14)    0         \n",
      "                                                                 \n",
      " time_distributed_41 (TimeDi  (None, None, 2, 2, 14)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " LSTM4 (ConvLSTM2D)          (None, None, 1, 1, 16)    7744      \n",
      "                                                                 \n",
      " MP4 (MaxPooling3D)          (None, None, 1, 1, 16)    0         \n",
      "                                                                 \n",
      " global_average_pooling3d_8   (None, 16)               0         \n",
      " (GlobalAveragePooling3D)                                        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 24)                408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,808\n",
      "Trainable params: 23,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classes = getClasses()\n",
    "model = createModel(classes)\n",
    "#model.build((100, 30, 30, 3))\n",
    "# model.summary()\n",
    "\n",
    "x_data, y_data = getLabeledVideo(video_path)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.33, random_state=42\n",
    ")\n",
    "# print(getVideo(x_train[0]).shape, y_train[0])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "fg = FrameGenerator(x_train, y_train, 10, training=True)\n",
    "# next(fg()).shape\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(), dtype=tf.int16),\n",
    ")\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(x_train, y_train, 10, training=True),\n",
    "    output_signature=output_signature,\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(x_test, y_test, 10), output_signature=output_signature\n",
    ")\n",
    "\n",
    "# ПОВЫШЕНИЕ ПРОИЗВОДИТЕЛЬНОСТИ\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "# val_dataset = val_dataset.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "train_dataset_batched = train_dataset.batch(32)\n",
    "val_dataset_batched = val_dataset.batch(32)\n",
    "\n",
    "#print(f\"Shape of training set of frames: {train_frames.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "21203a32",
   "metadata": {
    "cellId": "2zgrh0bs10kycsg843jmmp",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:10:41.462936970Z",
     "iopub.status.busy": "2023-11-11T11:10:42.420687Z",
     "iopub.status.idle": "2023-11-11T11:12:06.127680Z",
     "shell.execute_reply": "2023-11-11T11:12:06.125551Z",
     "shell.execute_reply.started": "2023-11-11T11:10:42.421565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     46/Unknown - 82s 2s/step - loss: 3.1504 - accuracy: 0.0522"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-26bf66a6a873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mt_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    t_b,\n",
    "    epochs=5,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(patience=2, monitor=\"val_loss\"),\n",
    ")\n",
    "\n",
    "os.chdir(model_dir)\n",
    "model.save(\"Model_CNN_LSTM_ver1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dd80e",
   "metadata": {
    "cellId": "lxu8prkfm6osciw55vf3hb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfa1d8",
   "metadata": {
    "cellId": "2mjlg9nrosjb7rel53cxhp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "20c059bf-175b-476f-b62a-bfe3258da653",
  "notebookPath": "Network.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
