{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f04d879",
   "metadata": {
    "cellId": "9hhxev8rmihyd1qlflsc3a"
   },
   "outputs": [],
   "source": [
    "# %pip install requests urllib if needed\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlencode\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import requests\n",
    "\n",
    "base_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download?\"\n",
    "public_key = \"https://disk.yandex.ru/d/5psHmaR1GCQq4w\"\n",
    "\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()[\"href\"]\n",
    "response = requests.get(download_url)\n",
    "\n",
    "dist_path = \"D\"\n",
    "zipfile = ZipFile(BytesIO(response.content))\n",
    "zipfile.extractall(path=dist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc283560",
   "metadata": {
    "cellId": "f3dntsdfgveucm1vkalya",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:08:42.417858128Z",
     "iopub.status.busy": "2023-11-11T11:08:43.331249Z",
     "iopub.status.idle": "2023-11-11T11:08:43.364560Z",
     "shell.execute_reply": "2023-11-11T11:08:43.363828Z",
     "shell.execute_reply.started": "2023-11-11T11:08:43.332509Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "from sys import getsizeof\n",
    "\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "video_path = \"videos\"\n",
    "main_dir = \"C:\\\\Users\\\\kseni\\\\JUPYTER\\\\DM-STAVROPOL\"\n",
    "model_dir = \"C:\\\\Users\\\\kseni\\\\JUPYTER\\\\DM-STAVROPOL\\\\models\"\n",
    "os.chdir(main_dir)\n",
    "\n",
    "\n",
    "def getClasses():\n",
    "    os.chdir(main_dir)\n",
    "    classes = []\n",
    "    with open(\"classes.csv\") as fp:\n",
    "        reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "        # next(reader, None)  # skip the headers\n",
    "        data_read = [row for row in reader]\n",
    "        classes = [x[1] for x in data_read[1:]]\n",
    "    return classes\n",
    "\n",
    "\n",
    "def createModel(classes):\n",
    "    input_shape = (None, 30, 30, 3)\n",
    "\n",
    "    model = models.Sequential()\n",
    " \n",
    "    # Define the Model Architecture.\n",
    "    ########################################################################################################################\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    # Flatten the output of CNN for LSTM input\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Reshape for LSTM input (assuming sequences of 10 frames)\n",
    "    model.add(layers.Reshape((1, -1)))\n",
    "\n",
    "    # LSTM layer\n",
    "    model.add(layers.LSTM(64, return_sequences=True))\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(len(classes), activation='softmax'))\n",
    "\n",
    "    return model\n",
    "    ########################################################################################################################\n",
    "     \n",
    "    # Display the models summary.\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Return the constructed convlstm model.\n",
    "    return model\n",
    "\n",
    "\n",
    "def getLabeledVideo(directory):\n",
    "    os.chdir(f\"{main_dir}/{directory}\")\n",
    "    categories = os.listdir()\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for category in range(len(categories)):\n",
    "        # print(f\"Категория: {categories[category]}\")\n",
    "        path = f\"{main_dir}/{directory}/{categories[category]}\"\n",
    "        os.chdir(path)\n",
    "        videos = os.listdir()\n",
    "        for video in videos:\n",
    "            video_path = os.getcwd() + f\"/{video}\"\n",
    "            x_data.append(video_path)\n",
    "            y_data.append(category)\n",
    "    return x_data, np.array(y_data)\n",
    "\n",
    "\n",
    "def getVideo(path_video):\n",
    "    vid_capture = cv2.VideoCapture(path_video)\n",
    "    video_numerized = []\n",
    "    if vid_capture.isOpened() == False:\n",
    "        print(\"Ошибка открытия видеофайла\")\n",
    "    else:\n",
    "        file_count = 0\n",
    "        while vid_capture.isOpened():\n",
    "            ret, frame = vid_capture.read()\n",
    "            if ret == True:\n",
    "                file_count += 1\n",
    "                frame = frame / 255.0\n",
    "                video_numerized.append(frame)\n",
    "            else:\n",
    "                break\n",
    "    return np.array(video_numerized)\n",
    "\n",
    "\n",
    "def batch_generator(x_data, y_data, batch_size):\n",
    "    for i in range(0, len(x_data), batch_size):\n",
    "        yield np.array(\n",
    "            list(map(getVideo, x_data[i : i + batch_size])), dtype=\"object\"\n",
    "        ), y_data[i : i + batch_size]\n",
    "\n",
    "\n",
    "def format_frames(frame, output_size):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size=(30, 30), frame_step=15):\n",
    "    # Read each video frame by frame\n",
    "    result = []\n",
    "    src = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "    need_length = 1 + (n_frames - 1) * frame_step\n",
    "\n",
    "    if need_length > video_length:\n",
    "        start = 0\n",
    "    else:\n",
    "        max_start = video_length - need_length\n",
    "        start = random.randint(0, max_start + 1)\n",
    "\n",
    "    src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "    # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "    ret, frame = src.read()\n",
    "    result.append(format_frames(frame, output_size))\n",
    "\n",
    "    for _ in range(n_frames - 1):\n",
    "        for _ in range(frame_step):\n",
    "            ret, frame = src.read()\n",
    "            if ret:\n",
    "                frame = format_frames(frame, output_size)\n",
    "                result.append(frame)\n",
    "            else:\n",
    "                result.append(np.zeros_like(result[0]))\n",
    "    src.release()\n",
    "    result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class FrameGenerator:\n",
    "    def __init__(self, video_paths, classes, n_frames, training=False):\n",
    "        \"\"\"Returns a set of frames with their associated label.\n",
    "\n",
    "        Args:\n",
    "          path: Video file paths.\n",
    "          n_frames: Number of frames.\n",
    "          training: Boolean to determine if training dataset is being created.\n",
    "        \"\"\"\n",
    "        self.video_paths = video_paths\n",
    "        self.classes = classes\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        # self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "        # self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "    def get_files_and_class_names(self):\n",
    "        video_paths = list(self.path.glob(\"*/*.avi\"))\n",
    "        classes = [p.parent.name for p in video_paths]\n",
    "        return video_paths, classes\n",
    "\n",
    "    def __call__(self):\n",
    "        # video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "        pairs = list(zip(self.video_paths, self.classes))\n",
    "\n",
    "        # if self.training:\n",
    "        # random.shuffle(pairs)\n",
    "\n",
    "        for path, name in pairs:\n",
    "            video_frames = frames_from_video_file(path, self.n_frames)\n",
    "            label = tf.keras.utils.to_categorical(name, 24)  # self.class_ids_for_name[name] # Encode labels\n",
    "            yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1eeb3a0",
   "metadata": {
    "cellId": "br23ul0qjlbbwe05shhvod",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:08:43.524250548Z",
     "iopub.status.busy": "2023-11-11T11:08:44.391450Z",
     "iopub.status.idle": "2023-11-11T11:08:44.860707Z",
     "shell.execute_reply": "2023-11-11T11:08:44.860121Z",
     "shell.execute_reply.started": "2023-11-11T11:08:44.392291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 30, 30, 6)         78        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 10, 10, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 8)         440       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 2, 2, 8)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 12)          396       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 2, 12)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                3136      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 24)                792       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6922 (27.04 KB)\n",
      "Trainable params: 6922 (27.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classes = getClasses()\n",
    "model = createModel(classes)\n",
    "#model.build((100, 30, 30, 3))\n",
    "# model.summary()\n",
    "\n",
    "x_data, y_data = getLabeledVideo(video_path)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_data, test_size=0.33, random_state=42\n",
    ")\n",
    "# print(getVideo(x_train[0]).shape, y_train[0])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "fg = FrameGenerator(x_train, y_train, 10, training=True)\n",
    "# next(fg()).shape\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(24,), dtype=tf.float32),\n",
    ")\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(x_train, y_train, 10, training=True),\n",
    "    output_signature=output_signature,\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(x_test, y_test, 10), output_signature=output_signature\n",
    ")\n",
    "\n",
    "# ПОВЫШЕНИЕ ПРОИЗВОДИТЕЛЬНОСТИ\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "# val_dataset = val_dataset.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "train_dataset_batched = train_dataset.batch(256)\n",
    "val_dataset_batched = val_dataset.batch(256)\n",
    "\n",
    "#print(f\"Shape of training set of frames: {train_frames.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21203a32",
   "metadata": {
    "cellId": "2zgrh0bs10kycsg843jmmp",
    "execution": {
     "iopub.execute_input": "2023-11-11T11:10:41.462936970Z",
     "iopub.status.busy": "2023-11-11T11:10:42.420687Z",
     "iopub.status.idle": "2023-11-11T11:12:06.127680Z",
     "shell.execute_reply": "2023-11-11T11:12:06.125551Z",
     "shell.execute_reply.started": "2023-11-11T11:10:42.421565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Input 0 of layer \"max_pooling2d_6\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (None, None, None, None, 6)\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None, None, 3), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_dataset_batched,\n\u001b[0;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m      4\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(model_dir)\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel_CNN_LSTM_ver1.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filefqukmt4_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\kseni\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_5' (type Sequential).\n    \n    Input 0 of layer \"max_pooling2d_6\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (None, None, None, None, 6)\n    \n    Call arguments received by layer 'sequential_5' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, None, None, None, 3), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    train_dataset_batched,\n",
    "    epochs=5,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(patience=2, monitor=\"val_loss\"),\n",
    ")\n",
    "\n",
    "os.chdir(model_dir)\n",
    "model.save(\"Model_CNN_LSTM_ver1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dd80e",
   "metadata": {
    "cellId": "lxu8prkfm6osciw55vf3hb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfa1d8",
   "metadata": {
    "cellId": "2mjlg9nrosjb7rel53cxhp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "notebookId": "20c059bf-175b-476f-b62a-bfe3258da653",
  "notebookPath": "Network.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
